{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40714873",
   "metadata": {},
   "source": [
    "ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df1a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bb4348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cv.pdf', 'model.pdf', 'vector.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"/krish Naik/Code files/Github_GenAi/GenAi_Code/vectorDB/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24a31649",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_loader=PyPDFDirectoryLoader(\"\\\\krish Naik\\\\Code files\\\\Github_GenAi\\\\GenAi_Code\\\\vectorDB\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dba46a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(directory_loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea285e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = directory_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b7486fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Muhammad Uzair \\nData Scientist & GenAI Engineer \\n uzairu471@gmail.com  +92 3248562515  Islamabad, Pakistan  15 Jun 2003 \\n LinkedIn  Github \\nPROFILE \\nWith 1 years of experience in Machine learning , Deep Lea rning and Generative AI, I have \\nsuccessfully implemented NLP and Generative AI projects using the MLOps Pipeline to make \\ndata-driven decisions. I excel in Machine learning, Neural Networks, Transformers, Python, \\nLang Chain, Llama Index, RAG, Vector Databases, Hugging  Face, and building reliable LLM \\napplications. Seeking to leverage my expertise to contribute to a forward -thinking team and \\ndrive impactful solutions in a dynamic, tech -driven environment. \\nSKILLS \\nPython: (DSA), Statistics, Deep Learning: (ANN | Pytorch)                                                             \\nMachine learning: Stacking Models, Boosting Models, Classification, Regression, Data Preprocessing, Feature \\nengineering, Pandas, Numpy, Scikit-learn.                                                                                                           \\nNatural Language Processing: (RNN | LSTM | Encoder Decoder | Attention |Transformer | BERT | GPT)  \\nGenerative AI: (Open AI, Mistral , Llama, Gemini, Embeddings, HuggingFace, RAG, Finetuning, AI Agents)       \\nLLM Framework: (Langchain | LlamaIndex)                                                                                                        \\nVector Databases: (FAISS | ChromaDB | Pinecone)                                                                                        \\nRestAPIs: (FastAPI)                                                                                                                                                  \\nFrontEnd:  (ReactJs)                                                                                                                                                       \\nDatabases: (MySQL | SQL |  MongoDB)                                                                                                                                   \\nCloud: (AWS | Azure)                                                                                                                                                  \\nVersion Control: (Git, Github) \\nPROFESSIONAL  EXPERIENCE \\n  Research Assistant, SmartLab-ICP                                                               Nov 2024 – Present | Peshawar, PK \\n• Published research on Urdu Fake News Detection using advanced machine learning and deep \\nlearning techniques. \\n• Fine-tuned LLMs for code generation using Parameter-Efficient Fine-Tuning methods like LoRA \\nand QLoRA. \\n• Built and fine-tuned transformer models (BERT, GPT, T5) and RAG-based systems for QA and \\nretrieval tasks. \\n• Applied deep learning with RNN, LSTM, and GRU models using TensorFlow and scikit-learn for \\nNLP solutions. \\n• Designed and deployed scalable AI/ML solutions for real-world NLP and multimodal applications \\nusing Python. \\n• Implemented GenAI workflows using LangChain, FAISS, Weaviate, and OpenAI APIs for RAG \\nand autonomous agents. \\n• Performed robust model training, tuning, and evaluation with tools like TensorBoard, MLflow, and \\nW&B. \\n• Integrated AI pipelines into backend systems with FastAPI, enabling cloud-ready deployment \\n(AWS). \\nMachine Learning Intern, CodeVenator         Jun 2023 – Oct 2024 | Peshawar, PK  \\n• Developed interactive Streamlit dashboards for classification and regression model deployment. \\n• Built robust web scraping pipelines to extract and structure data from diverse online sources. \\n• Executed comprehensive data preprocessing, cleaning, and augmentation to ensure consistency \\nacross formats. \\n• Worked on Market Sales prediction and data analysis projects.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd443214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77e8366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "further_split_doc=text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6122cf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(further_split_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd70ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
